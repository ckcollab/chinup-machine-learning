{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import neurolab as nl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#from sklearn import metrics\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "data_frame = pd.read_csv(\"personal_stats2.csv\")\n",
    "data_frame = data_frame[[\"Happiness\", \"Motivation\", \"Flexibility\", \"Strength\", \"Endurance\", \"Relationships\"]]\n",
    "\n",
    "# Get 80% of our dataset\n",
    "index_at_80_percent = int(len(data_frame) * .8)\n",
    "#truth_data = data_frame[:index_at_80_percent]\n",
    "#training_data = data_frame[index_at_80_percent:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first 80% as input and the following day as the target result\n",
    "training_input = data_frame[:index_at_80_percent]\n",
    "training_target = data_frame[1:index_at_80_percent + 1]\n",
    "\n",
    "# The final 20% same as above, current day as input next day as expected output\n",
    "test_input = data_frame[index_at_80_percent + 1: len(data_frame) - 1]\n",
    "test_target = data_frame[index_at_80_percent + 2:]\n",
    "\n",
    "# training_input = training_input / 10\n",
    "# training_target = training_target / 10\n",
    "# test_input = test_input / 10\n",
    "# test_target = test_target / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fmin_bfgs() got an unexpected keyword argument 'lr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-8a71ef794a7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#net = nl.net.newff([[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1]], 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eric/.virtualenvs/machine-learning/lib/python2.7/site-packages/neurolab/core.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \"\"\"\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eric/.virtualenvs/machine-learning/lib/python2.7/site-packages/neurolab/core.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, net, input, target, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTrainStop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'show'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eric/.virtualenvs/machine-learning/lib/python2.7/site-packages/neurolab/train/spo.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, net, input, target)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         x = fmin_bfgs(self.fcn, self.x.copy(), fprime=self.grad, callback=self.step,\n\u001b[0;32m---> 79\u001b[0;31m                       **self.kwargs)\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fmin_bfgs() got an unexpected keyword argument 'lr'"
     ]
    }
   ],
   "source": [
    "# Make 6 inputs, 20 neurons and 6 outputs\n",
    "net = nl.net.newff(\n",
    "    [\n",
    "        #[0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1]\n",
    "        [0, 10], [0, 10], [0, 10], [0, 10], [0, 10], [0, 10], \n",
    "    ], \n",
    "    [20, 6]\n",
    ")\n",
    "#net = nl.net.newff([[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1]], 1)\n",
    "\n",
    "err = net.train_gdx(training_input, training_target, lr=0.005, epochs=1000, show=15, goal=10)\n",
    "\n",
    "\n",
    "# Take the data and expand it into input -> output\n",
    "# truth_data_expanded = []\n",
    "# print dir(truth_data)\n",
    "# for truth in truth_data.items():\n",
    "#     print truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = '''\n",
    "Input -> 6 metrics with 1-10 in each\n",
    "Output -> Next days prediction\n",
    "\n",
    "Input layer has 6 inputs\n",
    "Output layer has 6 outputs OR 1 output \"happiness rating?\"\n",
    "\n",
    "Normalize data / 10\n",
    "Denormalize * 10\n",
    "'''\n",
    "\n",
    "#model = LogisticRegression()\n",
    "#model.fit(training_data, truth_data)\n",
    "#predicted = model.predict(training_data)\n",
    "#print metrics.classification_report(truth_data, predicted)\n",
    "#print metrics.confusion_matrix(truth_data, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"measurement\"][:,3]  -> can only tuple-index with a MultiIndex, google that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}